apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: default
data:
  prometheus.yml: |
    global:
      scrape_interval:     1m
      evaluation_interval: 1m
      # scrape_timeout is set to the global default (10s).

    scrape_configs:
    #  - {job_name: 'prometheus',   static_configs: [{targets: ['localhost:9090']}]}
    #  - {job_name: 'openid-proxy', static_configs: [{targets: ['openid-proxy.default.svc.cluster.local:8000']}]}
    #  - {job_name: 'nginx-log',    static_configs: [{targets: ['nginx.svc.cluster.local:8000']}]}
    #  - {job_name: 'grafana',      static_configs: [{targets: ['grafana.default.svc.cluster.local']}]}
    #  - {job_name: 'kube-state',   static_configs: [{targets: ['kube-state-metrics.default.svc.cluster.local:8080']}]}

      # should be able to annotate the services that support scraping, so we don't waste so much on errors
      - job_name: 'k8services'
        kubernetes_sd_configs: [{role: endpoints}]
        relabel_configs:
        # - source_labels:
        #     - __meta_kubernetes_namespace
        #     - __meta_kubernetes_service_name
        #   action: drop
        #   regex: default;kubernetes
          - source_labels:
              - __meta_kubernetes_namespace
            regex: default
            action: keep
          - source_labels: [__meta_kubernetes_service_name]
            target_label: job


      # seems like this would match more stuff, but all I get is coredns
      - job_name: 'coredns' 
        kubernetes_sd_configs: [{role: pod}]
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_container_port_name]
            regex: metrics
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: job

      - job_name: 'cadvisor'
        kubernetes_sd_configs: [{role: node}]
        scheme: https
        tls_config: {ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt}
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        metrics_path: /metrics/cadvisor
        
      - job_name: 'kubelets'
        
        scheme: https
        tls_config: {ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt}
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs: [{role: node}]
        
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
           

      - job_name: 'prober'
        scrape_interval: 1d
        metrics_path: /probe
        params:
          module: [https]
        static_configs:
          - targets:
            # sync with /my/doc/ssl/letsencrypt/run.py
            - bigast.com
            - www.bigast.com
            - bigasterisk.com
            - www.bigasterisk.com

        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: prober.default.svc.cluster.local
            
    alerting:
      alertmanagers:
        - static_configs:
          - targets:
             - alertmanager.default.svc.cluster.local

    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      - "rules.yml"
  rules.yml: |
    # reload with: inv rebuild-config

    # docs: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/
    # "Whenever the alert expression results in one or more vector
    # elements at a given point in time, the alert counts as active for
    # these elements' label sets."

    # also https://www.metricfire.com/blog/top-5-prometheus-alertmanager-gotchas/#Missing-metrics

    groups:
      - name: webcam
        rules:
          - alert: twinscam_pipeline_stopped
            expr: sum without (instance) (cam_pipeline_state{cam_pipeline_state="playing"}) < 1 or absent(cam_pipeline_state{cam_pipeline_state="playing"})
            for: 10m
            labels:
              severity: losingData
            annotations:
              summary: "twinscam recorder pipeline not running. See https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/webcam-record/logs"
          - alert: twinscam_not_advancing
            expr: rate(cam_stream_bytes{element="splitmux"}[3m]) < 0.2
            for: 10m
            labels:
              severity: losingData
            annotations:
              summary: "twinscam output bytes is advancing too slowly. See https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/webcam-record/logs"

      - name: Outages
        rules:
          - alert: powereagleStalled
            expr: rate(house_power_w[100m]) == 0
            for: 0m
            labels:
              severity: losingData
            annotations:
              summary: "power eagle data stalled"
              description: "logs at https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/power-eagle/logs"

          - alert: powereagleAbsent
            expr: absent_over_time(house_power_w[5m])
            for: 2m
            labels:
              severity: losingData
            annotations:
              summary: "power eagle data missing"
              description: "logs at https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/power-eagle/logs"

          - alert: wifi_scrape_errors
            expr: rate(poll_errors_total{job="wifi"}[2m]) > .1
            labels:
              severity: houseUsersAffected
            annotations:
              summary: "errors getting wifi users list"

          - alert: absent_mitmproxy
            expr: absent(process_resident_memory_bytes{job="mitmproxy"})
            labels:
              severity: houseUsersAffected
            annotations:
              summary: "mitmproxy metrics not responding. See https://bigasterisk.com/grafana/d/ix3hMAdMk/webfilter?orgId=1&from=now-12h&to=now and https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/mitmproxy (metrics actually come from webfilter.py plugin)"

          - alert: net_routes_sync
            expr: min(sync_is_up{job="net-routes"}) != 1
            for: 30m
            labels:
              severity: houseUsersAffected
            annotations:
              summary: "mitmproxy not syncing. See https://bigasterisk.com/grafana/d/ix3hMAdMk/webfilter?orgId=1&from=now-12h&to=now and https://bigasterisk.com/k/clusters/local/namespaces/default/deployments/net-routes"


      - name: alerts
        rules:
          - { alert: housePower, expr: "house_power_w > 3000", for: 20m, labels: { severity: waste }, annotations: { summary: "house power usage over 3KW" } }
          - alert: ssl_certs_expiring_soon
            expr: min((min_over_time(probe_ssl_earliest_cert_expiry[1d])-time())/86400) < 10
            labels:
              severity: futureUsersAffected
            annotations:
              summary: "cert expiring soon. See https://bigasterisk.com/grafana/d/z1YtDa3Gz/certs?orgId=1"