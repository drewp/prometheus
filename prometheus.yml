global:
  scrape_interval:     1m
  evaluation_interval: 1m
  # scrape_timeout is set to the global default (10s).

scrape_configs:
  # some based on https://github.com/prometheus/prometheus/blob/main/documentation/examples/prometheus-kubernetes.yml

  
  - job_name: "kubernetes-apiservers"
    scheme: https
    tls_config: { ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt }
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    kubernetes_sd_configs: [{role: endpoints}]

    relabel_configs:
      - source_labels:
          [
            __meta_kubernetes_namespace,
            __meta_kubernetes_service_name,
            __meta_kubernetes_endpoint_port_name,
          ]
        action: keep
        regex: default;kubernetes;https


  - job_name: "kubernetes-nodes"
    scheme: https
    tls_config: { ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt }
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    kubernetes_sd_configs: [{role: node}]

    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)


# see https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md
# for metric definitions
  - job_name: "kubernetes-cadvisor"
    scheme: https
    metrics_path: /metrics/cadvisor
    tls_config: { ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt }
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    kubernetes_sd_configs: [{role: node}]

    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)


  - job_name: 'k8services'
    kubernetes_sd_configs: [{role: endpoints}]
    relabel_configs:
      # To omit a service, add this at pod-level:
      #   annotations: { prometheus.io/scrape: "false" }
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        regex: false
        action: drop
      - source_labels: [__meta_kubernetes_service_name]
        regex: kubernetes
        action: drop
      - source_labels: [__meta_kubernetes_namespace]
        regex: default
        action: keep
      # mitmproxy has lots of ports. I expect this will be tuned to pick just one of them
      - source_labels: [__meta_kubernetes_service_name]
        regex: "mitmproxy"
        action: drop
      # only take owncloud db exporter, not the mysql
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_pod_container_port_number]
        regex: "owncloud-db;3306"
        action: drop
      # temporary until these svcs are fixed!
      - source_labels: [__meta_kubernetes_service_name]
        regex: "c3po|front-door-lock|openid-proxy|lanscape|net-routes|shortener|rdf-to-mqtt|reposync|bigfoaf-logins|asher4|numberone|registry-ui|kube-web-view|diarybot|blaster|sfd"
        action: drop
      - source_labels: [__meta_kubernetes_service_name]
        target_label: job
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: node
 

  # # seems like this would match more stuff, but all I get is coredns
  # - job_name: 'old_coredns' 
  #   kubernetes_sd_configs: [{role: pod}]
  #   relabel_configs:
  #     - source_labels: [__meta_kubernetes_pod_container_port_name]
  #       regex: metrics
  #       action: keep
  #     - source_labels: [__meta_kubernetes_pod_container_name]
  #       target_label: job

  - job_name: 'telegraf'
    scheme: http
    kubernetes_sd_configs: [{role: node}]
    relabel_configs:
      - source_labels: [__address__]
        regex: "(.*):(\\d+)"
        target_label: __address__
        replacement: "${1}:9273"
        action: replace
     

  - job_name: 'ntop'
    metrics_path: /lua/local/lanscape/main.lua
    static_configs:
      - targets:
        - 10.5.0.1:3000

  - job_name: 'ping'
    scrape_interval: 2m
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        # printer, since it falls out of ntop with no traffic at all. Or, we could poll ink status at http://10.2.0.37/general/status.html?pageid=1
        - 10.2.0.37
        # garage, until it's on k3s which will make lots of traffic
        - 10.5.0.14
        # frontbed, for monitoring
        - 10.5.0.17

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: prober

  - job_name: 'prober'
    scrape_interval: 1d
    metrics_path: /probe
    params:
      module: [https]
    static_configs:
      - targets:
        # sync with /my/doc/ssl/letsencrypt/run.py

    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: prober
        
alerting:
  alertmanagers:
    - static_configs:
      - targets:
          - alertmanager.default.svc.cluster.local.

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "rules.yml"
